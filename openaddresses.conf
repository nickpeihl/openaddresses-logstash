input {
  file {
    path => ["${LOGSTASH_DIR}/*.csv"]
    start_position => "beginning"
    sincedb_path => "${LOGSTASH_DIR}/openaddresses.db"
  }
}

filter {
  csv {
    separator => ","
    columns => ["lon", "lat", "number", "street", "unit", "city", "district", "region", "postcode", "id", "hash"]
  }

  mutate {
    remove_field => ["@timestamp", "@version", "message","path","host"]
    convert => { "lon" => "float" }
    convert => { "lat" => "float" }
    rename => { "hash" => "[@metadata][hash]" }
    rename => {
        "lon" => "[location][lon]"
        "lat" => "[location][lat]"
    }
  }
}

output {
  elasticsearch {
    index => "openaddresses"
    hosts => ["localhost:9200"]
    user => "elastic"
    password => "changeme"
    action => "update"
    document_id => "%{[@metadata][hash]}"
    doc_as_upsert => true
    template      => "${LOGSTASH_DIR}/openaddresses.json"
    template_name => "openaddresses"
    template_overwrite => true
    sniffing => true
    sniffing_delay => 999
  }
}
